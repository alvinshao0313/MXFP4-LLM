{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "手动输入",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": "${command:pickArgs}"
        },
        {
            "name": "预置超参",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--double_quant",
                "false",
                "--model",
                "meta-llama/Meta-Llama-3-8B",
                "--seed",
                "0",
                "--tasks",
                "none",
                "--num_fewshot",
                "none",
                "--eval_ppl",
                "true",
                "--w_elem_format_linear",
                "fp4_e2m1",
                "--a_elem_format_linear",
                "fp4_e2m1",
                "--scale_bits_linear",
                "16",
                "--block_size_linear",
                "32",
                "--A_elem_format_matmul",
                "none",
                "--B_elem_format_matmul",
                "none",
                "--scale_bits_matmul",
                "16",
                "--block_size_matmul",
                "32",
                "--w_elem_format_ln",
                "none",
                "--a_elem_format_ln",
                "none",
                "--scale_bits_ln",
                "16",
                "--block_size_ln",
                "16",
                "--w_elem_format_head",
                "none",
                "--a_elem_format_head",
                "none",
                "--scale_bits_head",
                "16",
                "--block_size_head",
                "16",
                "--auto_dtype",
                "true",
                "--custom_cuda",
                "true",
                "--a_scale_mode",
                "2",
                "--w_scale_mode",
                "2",
                "--A_scale_mode",
                "2",
                "--B_scale_mode",
                "2",
                "--per_tensor",
                "false",
                "--rotate",
                "true",
                "--rotate_mode",
                "group_hadamard",
                "--rotate_kv",
                "true",
                "--sorting_transform",
                "none",
                "--group_rotate_kv",
                "false",
                "--kv_quant_only",
                "true",
                "--kv_tokenwise",
                "true",
                "--gptq",
                "true",
                "--sorting_transform",
                "none",
                "--smooth",
                "/home/shaoyuantian/program/MXFP4-LLM/smooth_scales/Meta-Llama-3-8B_per_smooth_scales.pt"
            ]
        }
    ]
}