{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb2f2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mx\n",
    "from mx.mx_ops import quantize_mx_op, get_mx_quantize_params, apply_mx_quantize_with_param\n",
    "\n",
    "from mx.elemwise_ops import quantize_elemwise_op\n",
    "from mx.specs import MxSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de660bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaoyuantian/anaconda3/envs/mx-qllm/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weight shape: torch.Size([1024, 4096])\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", torch_dtype=torch.float16)\n",
    "model.eval()\n",
    "w = model.model.layers[0].self_attn.k_proj.weight.data.clone()\n",
    "print(\"Original weight shape:\", w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7c36fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_specs = MxSpecs()\n",
    "mx_specs[\"custom_cuda\"] = True\n",
    "mx_specs[\"w_elem_format\"] = \"fp4_e2m1\"\n",
    "mx_specs[\"w_scale_mode\"] = 0\n",
    "mx_specs[\"block_size\"] = 32\n",
    "mx_specs[\"round_mx_output\"] = \"nearest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "42d3277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_mx_w(weight):\n",
    "    dtype = weight.dtype\n",
    "    # element-wise quantize for input\n",
    "    bf_weight = quantize_elemwise_op(\n",
    "            weight.float(), mx_specs=mx_specs, round=mx_specs[\"round_weight\"]\n",
    "        )\n",
    "    if not mx_specs['double_quant']:\n",
    "        qis_weight = quantize_mx_op(\n",
    "            bf_weight,\n",
    "            mx_specs,\n",
    "            elem_format=mx_specs['w_elem_format'],\n",
    "            scale_mode=mx_specs['w_scale_mode'],\n",
    "            axes=[-1],\n",
    "            round=mx_specs[\"round_mx_output\"],\n",
    "        )\n",
    "    elif mx_specs['double_quant']: \n",
    "        def scale_mode_to_elem_format(scale_mode):\n",
    "            if scale_mode == 143:\n",
    "                return 'fp8_e4m3'\n",
    "            elif scale_mode == 152:\n",
    "                return 'fp8_e5m2'\n",
    "            elif scale_mode == 0:\n",
    "                return 'e8m0'\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported scale mode: {scale_mode}\")\n",
    "        w_scale, _, _, q_w = get_mx_quantize_params(\n",
    "            bf_weight,\n",
    "            mx_specs,\n",
    "            elem_format=mx_specs['w_elem_format'],\n",
    "            scale_mode=2,\n",
    "            axes=[-1],\n",
    "            round=mx_specs[\"round_mx_output\"],\n",
    "        )\n",
    "        scale_mx_specs = mx_specs.copy()\n",
    "        scale_mx_specs['block_size'] = -1\n",
    "        q_w_scale = quantize_mx_op(\n",
    "                w_scale,\n",
    "                scale_mx_specs,\n",
    "                elem_format=scale_mode_to_elem_format(mx_specs['w_scale_mode']),\n",
    "                scale_mode=2,\n",
    "                axes=[-1],\n",
    "                round=scale_mx_specs[\"round_mx_output\"],\n",
    "            )\n",
    "        qis_weight = q_w_scale * q_w\n",
    "        \n",
    "    return qis_weight.to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "54af686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_w = quantize_mx_w(w.to('cuda:7'))\n",
    "mx_specs['double_quant'] = True\n",
    "fdq_w = quantize_mx_w(w.to('cuda:7'))\n",
    "a = torch.nn.functional.mse_loss(w.to('cuda:7'), fq_w)\n",
    "b = torch.nn.functional.mse_loss(w.to('cuda:7'), fdq_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e90055e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_weight = quantize_elemwise_op(\n",
    "            w.to('cuda:7').float(), mx_specs=mx_specs, round=mx_specs[\"round_weight\"]\n",
    "        )\n",
    "w_scale1, _, _, q_w1 = get_mx_quantize_params(\n",
    "    bf_weight,\n",
    "    mx_specs,\n",
    "    elem_format=mx_specs['w_elem_format'],\n",
    "    scale_mode=mx_specs['w_scale_mode'],\n",
    "    axes=[-1],\n",
    "    round=mx_specs[\"round_mx_output\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ff4205d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_scale2, _, _, q_w2 = get_mx_quantize_params(\n",
    "    bf_weight,\n",
    "    mx_specs,\n",
    "    elem_format=mx_specs['w_elem_format'],\n",
    "    scale_mode=2,\n",
    "    axes=[-1],\n",
    "    round=mx_specs[\"round_mx_output\"],\n",
    "        )\n",
    "def scale_mode_to_elem_format(scale_mode):\n",
    "            if scale_mode == 143:\n",
    "                return 'fp8_e4m3'\n",
    "            elif scale_mode == 152:\n",
    "                return 'fp8_e5m2'\n",
    "            elif scale_mode == 0:\n",
    "                return 'e8m0'\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported scale mode: {scale_mode}\")\n",
    "scale_mx_specs = mx_specs.copy()\n",
    "scale_mx_specs['block_size'] = -1\n",
    "q_w_scale = quantize_mx_op(\n",
    "        w_scale2,\n",
    "        scale_mx_specs,\n",
    "        elem_format=scale_mode_to_elem_format(mx_specs['w_scale_mode']),\n",
    "        scale_mode=2,\n",
    "        axes=[-1],\n",
    "        round=scale_mx_specs[\"round_mx_output\"],\n",
    "    )\n",
    "qis_weight = q_w_scale * q_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0fda36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tile_quantization_loss(original, quantized, block_size=32, loss_type='mse', axis=-1):\n",
    "    \"\"\"\n",
    "    计算每个 tile 的量化损失 - 支持权重量化\n",
    "    \n",
    "    Args:\n",
    "        original: 原始张量\n",
    "        quantized: 量化后的张量\n",
    "        block_size: tile 大小\n",
    "        loss_type: 损失类型 ('mse', 'mae', 'cosine', 'snr')\n",
    "        axis: 分 tile 的维度（-1 表示最后一个维度）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 确保张量形状一致\n",
    "    assert original.shape == quantized.shape\n",
    "    \n",
    "    # 获取指定轴的大小\n",
    "    axis_size = original.shape[axis]\n",
    "    num_tiles = (axis_size + block_size - 1) // block_size\n",
    "    padded_size = num_tiles * block_size\n",
    "    \n",
    "    # 计算 padding\n",
    "    if padded_size > axis_size:\n",
    "        padding = padded_size - axis_size\n",
    "        # 创建 padding 配置：只在指定轴的末尾 padding\n",
    "        pad_config = [0, 0] * original.ndim\n",
    "        pad_config[-(axis+1)*2 + 1] = padding  # 在指定轴末尾padding\n",
    "        \n",
    "        original_padded = torch.nn.functional.pad(original, pad_config)\n",
    "        quantized_padded = torch.nn.functional.pad(quantized, pad_config)\n",
    "    else:\n",
    "        original_padded = original\n",
    "        quantized_padded = quantized\n",
    "    \n",
    "    # 重塑为 tiles\n",
    "    # 将指定轴移到最后，然后 reshape\n",
    "    original_moved = original_padded.moveaxis(axis, -1)\n",
    "    quantized_moved = quantized_padded.moveaxis(axis, -1)\n",
    "    \n",
    "    # 计算前面维度的总大小\n",
    "    front_dims = original_moved.shape[:-1]\n",
    "    total_front = torch.prod(torch.tensor(front_dims)).item()\n",
    "    \n",
    "    # 重塑为 [total_front * num_tiles, block_size]\n",
    "    original_tiles = original_moved.reshape(total_front, num_tiles, block_size).reshape(-1, block_size)\n",
    "    quantized_tiles = quantized_moved.reshape(total_front, num_tiles, block_size).reshape(-1, block_size)\n",
    "    \n",
    "    # 计算每个 tile 的损失\n",
    "    if loss_type == 'mse':\n",
    "        tile_losses = torch.mean((original_tiles - quantized_tiles) ** 2, dim=1)\n",
    "    elif loss_type == 'mae':\n",
    "        tile_losses = torch.mean(torch.abs(original_tiles - quantized_tiles), dim=1)\n",
    "    elif loss_type == 'cosine':\n",
    "        cosine_sim = torch.nn.functional.cosine_similarity(original_tiles, quantized_tiles, dim=1)\n",
    "        tile_losses = 1 - cosine_sim\n",
    "    elif loss_type == 'snr':\n",
    "        signal_power = torch.mean(original_tiles ** 2, dim=1)\n",
    "        noise_power = torch.mean((original_tiles - quantized_tiles) ** 2, dim=1)\n",
    "        tile_losses = -10 * torch.log10(signal_power / (noise_power + 1e-8))\n",
    "    \n",
    "    # 重塑回原来的结构：[total_front, num_tiles]\n",
    "    tile_losses = tile_losses.reshape(total_front, num_tiles)\n",
    "    \n",
    "    return tile_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e5a92488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'WenQuanYi Micro Hei']\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "# 增强版绘图函数 - 修复中文显示\n",
    "def plot_detailed_quantization_analysis(q_t1_loss, q_t2_loss, q_t1_label='scale_mode=0', q_t2_label='scale_mode=2'):\n",
    "    \"\"\"\n",
    "    绘制详细的量化损失分析图\n",
    "    \"\"\"\n",
    "    \n",
    "    # 转换为 numpy\n",
    "    q_t1_np = q_t1_loss.cpu().numpy() if hasattr(q_t1_loss, 'cpu') else q_t1_loss\n",
    "    q_t2_np = q_t2_loss.cpu().numpy() if hasattr(q_t2_loss, 'cpu') else q_t2_loss\n",
    "    \n",
    "    num_tiles = len(q_t1_np)\n",
    "    tile_indices = np.arange(num_tiles)\n",
    "    \n",
    "    # 创建子图\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. 柱状图对比\n",
    "    width = 0.35\n",
    "    axes[0,0].bar(tile_indices - width/2, q_t1_np, width, \n",
    "                  label=q_t1_label, color='lightblue', alpha=0.8)\n",
    "    axes[0,0].bar(tile_indices + width/2, q_t2_np, width, \n",
    "                  label=q_t2_label, color='darkblue', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Group Index (Tile Index)')\n",
    "    axes[0,0].set_ylabel('Quantization Loss (MSE)')\n",
    "    axes[0,0].set_title('Quantization Loss Comparison')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 差值分析\n",
    "    diff = q_t1_np - q_t2_np\n",
    "    colors = ['green' if d > 0 else 'red' for d in diff]\n",
    "    axes[0,1].bar(tile_indices, diff, color=colors, alpha=0.7)\n",
    "    axes[0,1].set_xlabel('Group Index (Tile Index)')\n",
    "    axes[0,1].set_ylabel('Loss Difference (q_t1 - q_t2)')\n",
    "    axes[0,1].set_title('Loss Difference (Green: scale_mode=2 Better)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 3. 改进百分比\n",
    "    improvement = (diff / q_t1_np) * 100\n",
    "    axes[1,0].bar(tile_indices, improvement, color='orange', alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Group Index (Tile Index)')\n",
    "    axes[1,0].set_ylabel('Improvement Percentage (%)')\n",
    "    axes[1,0].set_title(f'{q_t1_label} vs {q_t2_label} Improvement')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 4. 累积损失\n",
    "    cumsum_t1 = np.cumsum(q_t1_np)\n",
    "    cumsum_t2 = np.cumsum(q_t2_np)\n",
    "    axes[1,1].plot(tile_indices, cumsum_t1, 'o-', label=q_t1_label, \n",
    "                   color='lightblue', linewidth=2, markersize=4)\n",
    "    axes[1,1].plot(tile_indices, cumsum_t2, 's-', label=q_t2_label, \n",
    "                   color='darkblue', linewidth=2, markersize=4)\n",
    "    axes[1,1].set_xlabel('Group Index (Tile Index)')\n",
    "    axes[1,1].set_ylabel('Cumulative Loss')\n",
    "    axes[1,1].set_title('Cumulative Quantization Loss')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Quantization Loss Statistical Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Metric':<20} {q_t1_label:<15} {q_t2_label:<15} {'Improvement%':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Average Loss':<20} {np.mean(q_t1_np):<15.6f} {np.mean(q_t2_np):<15.6f} {np.mean(improvement):<10.2f}\")\n",
    "    print(f\"{'Total Loss':<20} {np.sum(q_t1_np):<15.6f} {np.sum(q_t2_np):<15.6f} {(np.sum(diff)/np.sum(q_t1_np)*100):<10.2f}\")\n",
    "    print(f\"{'Max Loss':<20} {np.max(q_t1_np):<15.6f} {np.max(q_t2_np):<15.6f} {np.max(improvement):<10.2f}\")\n",
    "    print(f\"{'Min Loss':<20} {np.min(q_t1_np):<15.6f} {np.min(q_t2_np):<15.6f} {np.min(improvement):<10.2f}\")\n",
    "    print(f\"{'Std Dev':<20} {np.std(q_t1_np):<15.6f} {np.std(q_t2_np):<15.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "19e8b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaled_data_histograms(scaled_pot, scaled_fp16, bins=100):\n",
    "    \"\"\"\n",
    "    绘制两种缩放数据的直方图对比\n",
    "    \"\"\"\n",
    "    \n",
    "    # 转换为 numpy 数组\n",
    "    scaled_pot_np = scaled_pot.cpu().numpy() if hasattr(scaled_pot, 'cpu') else scaled_pot\n",
    "    scaled_fp16_np = scaled_fp16.cpu().numpy() if hasattr(scaled_fp16, 'cpu') else scaled_fp16\n",
    "    \n",
    "    # 创建子图\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. 重叠直方图\n",
    "    axes[0,0].hist(scaled_pot_np, bins=bins, alpha=0.7, label='PoT Scale (scale_mode=0)', \n",
    "                   color='lightblue', density=True)\n",
    "    axes[0,0].hist(scaled_fp16_np, bins=bins, alpha=0.7, label='FP16 Scale (scale_mode=2)', \n",
    "                   color='darkblue', density=True)\n",
    "    axes[0,0].set_xlabel('Scaled Values')\n",
    "    axes[0,0].set_ylabel('Density')\n",
    "    axes[0,0].set_title('Overlapped Histograms of Scaled Data')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 分别的直方图 - PoT\n",
    "    axes[0,1].hist(scaled_pot_np, bins=bins, color='lightblue', alpha=0.8)\n",
    "    axes[0,1].set_xlabel('Scaled Values')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].set_title('PoT Scale Distribution (scale_mode=0)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 分别的直方图 - FP16\n",
    "    axes[1,0].hist(scaled_fp16_np, bins=bins, color='darkblue', alpha=0.8)\n",
    "    axes[1,0].set_xlabel('Scaled Values')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].set_title('FP16 Scale Distribution (scale_mode=2)')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 累积分布函数对比\n",
    "    sorted_pot = np.sort(scaled_pot_np)\n",
    "    sorted_fp16 = np.sort(scaled_fp16_np)\n",
    "    y_pot = np.arange(1, len(sorted_pot) + 1) / len(sorted_pot)\n",
    "    y_fp16 = np.arange(1, len(sorted_fp16) + 1) / len(sorted_fp16)\n",
    "    \n",
    "    axes[1,1].plot(sorted_pot, y_pot, label='PoT Scale', color='lightblue', linewidth=2)\n",
    "    axes[1,1].plot(sorted_fp16, y_fp16, label='FP16 Scale', color='darkblue', linewidth=2)\n",
    "    axes[1,1].set_xlabel('Scaled Values')\n",
    "    axes[1,1].set_ylabel('Cumulative Probability')\n",
    "    axes[1,1].set_title('Cumulative Distribution Functions')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Scaled Data Statistical Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Metric':<20} {'PoT Scale':<15} {'FP16 Scale':<15} {'Difference':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Mean':<20} {np.mean(scaled_pot_np):<15.6f} {np.mean(scaled_fp16_np):<15.6f} {np.mean(scaled_pot_np) - np.mean(scaled_fp16_np):<15.6f}\")\n",
    "    print(f\"{'Std Dev':<20} {np.std(scaled_pot_np):<15.6f} {np.std(scaled_fp16_np):<15.6f} {np.std(scaled_pot_np) - np.std(scaled_fp16_np):<15.6f}\")\n",
    "    print(f\"{'Min':<20} {np.min(scaled_pot_np):<15.6f} {np.min(scaled_fp16_np):<15.6f} {np.min(scaled_pot_np) - np.min(scaled_fp16_np):<15.6f}\")\n",
    "    print(f\"{'Max':<20} {np.max(scaled_pot_np):<15.6f} {np.max(scaled_fp16_np):<15.6f} {np.max(scaled_pot_np) - np.max(scaled_fp16_np):<15.6f}\")\n",
    "    print(f\"{'Median':<20} {np.median(scaled_pot_np):<15.6f} {np.median(scaled_fp16_np):<15.6f} {np.median(scaled_pot_np) - np.median(scaled_fp16_np):<15.6f}\")\n",
    "    print(f\"{'25th Percentile':<20} {np.percentile(scaled_pot_np, 25):<15.6f} {np.percentile(scaled_fp16_np, 25):<15.6f} {np.percentile(scaled_pot_np, 25) - np.percentile(scaled_fp16_np, 25):<15.6f}\")\n",
    "    print(f\"{'75th Percentile':<20} {np.percentile(scaled_pot_np, 75):<15.6f} {np.percentile(scaled_fp16_np, 75):<15.6f} {np.percentile(scaled_pot_np, 75) - np.percentile(scaled_fp16_np, 75):<15.6f}\")\n",
    "    \n",
    "    # 计算分布相似性\n",
    "    from scipy import stats\n",
    "    ks_stat, ks_p = stats.ks_2samp(scaled_pot_np, scaled_fp16_np)\n",
    "    print(f\"\\nKolmogorov-Smirnov Test:\")\n",
    "    print(f\"KS Statistic: {ks_stat:.6f}\")\n",
    "    print(f\"P-value: {ks_p:.6f}\")\n",
    "    print(f\"Distributions are {'similar' if ks_p > 0.05 else 'significantly different'} (α=0.05)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bb1a1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_hadamard_transform import hadamard_transform\n",
    "import math\n",
    "# token_roted = hadamard_transform(token.reshape(-1, token.shape[0] // 32,\n",
    "#                                                       32), scale=1 / math.sqrt(32)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8133f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_tile_details(original, quantized, tile_index, block_size=32, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    分析指定tile的详细量化情况\n",
    "    \n",
    "    Args:\n",
    "        original: 原始张量\n",
    "        quantized: 量化后的张量\n",
    "        tile_index: 要分析的tile索引\n",
    "        block_size: tile大小\n",
    "        title_prefix: 图表标题前缀\n",
    "    \"\"\"\n",
    "    \n",
    "    # 转换为numpy\n",
    "    original_np = original.cpu().numpy() if hasattr(original, 'cpu') else original\n",
    "    quantized_np = quantized.cpu().numpy() if hasattr(quantized, 'cpu') else quantized\n",
    "    \n",
    "    # 计算padding并重塑为tiles\n",
    "    seq_len = len(original_np)\n",
    "    num_tiles = (seq_len + block_size - 1) // block_size\n",
    "    padded_len = num_tiles * block_size\n",
    "    \n",
    "    if padded_len > seq_len:\n",
    "        padding = padded_len - seq_len\n",
    "        original_padded = np.pad(original_np, (0, padding))\n",
    "        quantized_padded = np.pad(quantized_np, (0, padding))\n",
    "    else:\n",
    "        original_padded = original_np\n",
    "        quantized_padded = quantized_np\n",
    "    \n",
    "    # 重塑为tiles\n",
    "    original_tiles = original_padded.reshape(-1, block_size)\n",
    "    quantized_tiles = quantized_padded.reshape(-1, block_size)\n",
    "    \n",
    "    # 获取指定tile的数据\n",
    "    orig_tile = original_tiles[tile_index]\n",
    "    quant_tile = quantized_tiles[tile_index]\n",
    "    \n",
    "    # 计算每个元素的损失\n",
    "    element_losses = (orig_tile - quant_tile) ** 2\n",
    "    element_indices = np.arange(block_size)\n",
    "    \n",
    "    # 创建详细分析图\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. 原始值 vs 量化值对比\n",
    "    axes[0,0].plot(element_indices, orig_tile, 'o-', label='Original', \n",
    "                   color='blue', linewidth=2, markersize=4)\n",
    "    axes[0,0].plot(element_indices, quant_tile, 's-', label='Quantized', \n",
    "                   color='red', linewidth=2, markersize=4)\n",
    "    axes[0,0].set_xlabel('Element Index in Tile')\n",
    "    axes[0,0].set_ylabel('Value')\n",
    "    axes[0,0].set_title(f'{title_prefix}Tile {tile_index}: Original vs Quantized')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 每个元素的量化误差\n",
    "    axes[0,1].bar(element_indices, orig_tile - quant_tile, \n",
    "                  color='orange', alpha=0.7)\n",
    "    axes[0,1].set_xlabel('Element Index in Tile')\n",
    "    axes[0,1].set_ylabel('Quantization Error (Original - Quantized)')\n",
    "    axes[0,1].set_title(f'Tile {tile_index}: Quantization Error per Element')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 3. 每个元素的平方误差（MSE贡献）\n",
    "    colors = ['red' if loss == np.max(element_losses) else 'lightcoral' for loss in element_losses]\n",
    "    bars = axes[1,0].bar(element_indices, element_losses, color=colors, alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Element Index in Tile')\n",
    "    axes[1,0].set_ylabel('Squared Error (MSE Contribution)')\n",
    "    axes[1,0].set_title(f'Tile {tile_index}: MSE Contribution per Element')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 标记最大损失的元素\n",
    "    max_loss_idx = np.argmax(element_losses)\n",
    "    axes[1,0].annotate(f'Max Loss\\nIndex: {max_loss_idx}\\nValue: {element_losses[max_loss_idx]:.6f}',\n",
    "                       xy=(max_loss_idx, element_losses[max_loss_idx]),\n",
    "                       xytext=(max_loss_idx + 3, element_losses[max_loss_idx] * 1.2),\n",
    "                       arrowprops=dict(arrowstyle='->', color='black'),\n",
    "                       fontsize=10, ha='left')\n",
    "    \n",
    "    # 4. 相对误差百分比\n",
    "    relative_error = np.abs(orig_tile - quant_tile) / (np.abs(orig_tile) + 1e-8) * 100\n",
    "    axes[1,1].bar(element_indices, relative_error, color='purple', alpha=0.7)\n",
    "    axes[1,1].set_xlabel('Element Index in Tile')\n",
    "    axes[1,1].set_ylabel('Relative Error (%)')\n",
    "    axes[1,1].set_title(f'Tile {tile_index}: Relative Error per Element')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印详细统计信息\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Detailed Analysis for {title_prefix}Tile {tile_index}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile MSE: {np.mean(element_losses):.8f}\")\n",
    "    print(f\"Tile Max Squared Error: {np.max(element_losses):.8f} (at index {max_loss_idx})\")\n",
    "    print(f\"Tile Min Squared Error: {np.min(element_losses):.8f}\")\n",
    "    print(f\"Tile Mean Absolute Error: {np.mean(np.abs(orig_tile - quant_tile)):.8f}\")\n",
    "    print()\n",
    "    \n",
    "    # 找出损失最大的几个元素\n",
    "    top_loss_indices = np.argsort(element_losses)[-5:][::-1]  # 前5个最大损失\n",
    "    print(\"Top 5 elements with highest squared error:\")\n",
    "    print(f\"{'Index':<8} {'Original':<12} {'Quantized':<12} {'Error':<12} {'Squared Error':<15} {'Rel Error %':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    for idx in top_loss_indices:\n",
    "        orig_val = orig_tile[idx]\n",
    "        quant_val = quant_tile[idx]\n",
    "        error = orig_val - quant_val\n",
    "        sq_error = element_losses[idx]\n",
    "        rel_error = np.abs(error) / (np.abs(orig_val) + 1e-8) * 100\n",
    "        print(f\"{idx:<8} {orig_val:<12.6f} {quant_val:<12.6f} {error:<12.6f} {sq_error:<15.8f} {rel_error:<12.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "869857b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rotation_effect(original_loss, rotated_loss, title=\"Rotation Effect Analysis\"):\n",
    "    \"\"\"\n",
    "    比较旋转前后的量化损失\n",
    "    \n",
    "    Args:\n",
    "        original_loss: 旋转前的量化损失\n",
    "        rotated_loss: 旋转后的量化损失\n",
    "        title: 图表标题\n",
    "    \"\"\"\n",
    "    \n",
    "    # 转换为 numpy\n",
    "    orig_np = original_loss.cpu().numpy() if hasattr(original_loss, 'cpu') else original_loss\n",
    "    rot_np = rotated_loss.cpu().numpy() if hasattr(rotated_loss, 'cpu') else rotated_loss\n",
    "    \n",
    "    num_tiles = len(orig_np)\n",
    "    tile_indices = np.arange(num_tiles)\n",
    "    \n",
    "    # 计算损失变化\n",
    "    loss_diff = rot_np - orig_np  # 正值表示旋转后损失增加\n",
    "    loss_ratio = rot_np / (orig_np + 1e-8)  # 损失比率\n",
    "    loss_change_percent = (loss_diff / (orig_np + 1e-8)) * 100  # 损失变化百分比\n",
    "    \n",
    "    # 创建详细分析图\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. 旋转前后损失对比\n",
    "    width = 0.35\n",
    "    axes[0,0].bar(tile_indices - width/2, orig_np, width, \n",
    "                  label='Before Rotation', color='lightblue', alpha=0.8)\n",
    "    axes[0,0].bar(tile_indices + width/2, rot_np, width, \n",
    "                  label='After Rotation', color='orange', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Tile Index')\n",
    "    axes[0,0].set_ylabel('Quantization Loss (MSE)')\n",
    "    axes[0,0].set_title('Quantization Loss: Before vs After Rotation')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 损失变化（绝对值）\n",
    "    colors = ['red' if d > 0 else 'green' for d in loss_diff]\n",
    "    bars = axes[0,1].bar(tile_indices, loss_diff, color=colors, alpha=0.7)\n",
    "    axes[0,1].set_xlabel('Tile Index')\n",
    "    axes[0,1].set_ylabel('Loss Change (After - Before)')\n",
    "    axes[0,1].set_title('Loss Change after Rotation (Red: Increased, Green: Decreased)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 3. 损失变化百分比\n",
    "    colors_pct = ['red' if p > 0 else 'green' for p in loss_change_percent]\n",
    "    axes[1,0].bar(tile_indices, loss_change_percent, color=colors_pct, alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Tile Index')\n",
    "    axes[1,0].set_ylabel('Loss Change Percentage (%)')\n",
    "    axes[1,0].set_title('Percentage Change in Loss after Rotation')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 4. 损失比率分布\n",
    "    axes[1,1].hist(loss_ratio, bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
    "    axes[1,1].axvline(x=1, color='red', linestyle='--', linewidth=2, label='No Change (ratio=1)')\n",
    "    axes[1,1].set_xlabel('Loss Ratio (After/Before)')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].set_title('Distribution of Loss Ratios')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 统计分析\n",
    "    increased_tiles = np.where(loss_diff > 0)[0]\n",
    "    decreased_tiles = np.where(loss_diff < 0)[0]\n",
    "    unchanged_tiles = np.where(np.abs(loss_diff) < 1e-8)[0]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{title}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total tiles: {num_tiles}\")\n",
    "    print(f\"Tiles with increased loss: {len(increased_tiles)} ({len(increased_tiles)/num_tiles*100:.1f}%)\")\n",
    "    print(f\"Tiles with decreased loss: {len(decreased_tiles)} ({len(decreased_tiles)/num_tiles*100:.1f}%)\")\n",
    "    print(f\"Tiles with unchanged loss: {len(unchanged_tiles)} ({len(unchanged_tiles)/num_tiles*100:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Overall Statistics:\")\n",
    "    print(f\"{'Metric':<25} {'Before Rotation':<15} {'After Rotation':<15} {'Change':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Mean Loss':<25} {np.mean(orig_np):<15.8f} {np.mean(rot_np):<15.8f} {np.mean(loss_diff):<15.8f}\")\n",
    "    print(f\"{'Total Loss':<25} {np.sum(orig_np):<15.6f} {np.sum(rot_np):<15.6f} {np.sum(loss_diff):<15.6f}\")\n",
    "    print(f\"{'Max Loss':<25} {np.max(orig_np):<15.8f} {np.max(rot_np):<15.8f} {np.max(orig_np) - np.max(rot_np):<15.8f}\")\n",
    "    print(f\"{'Min Loss':<25} {np.min(orig_np):<15.8f} {np.min(rot_np):<15.8f} {np.min(orig_np) - np.min(rot_np):<15.8f}\")\n",
    "    print(f\"{'Std Dev':<25} {np.std(orig_np):<15.8f} {np.std(rot_np):<15.8f} {np.std(rot_np) - np.std(orig_np):<15.8f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Loss Change Analysis:\")\n",
    "    print(f\"Mean loss change: {np.mean(loss_diff):.8f}\")\n",
    "    print(f\"Mean percentage change: {np.mean(loss_change_percent):.2f}%\")\n",
    "    print(f\"Max loss increase: {np.max(loss_diff):.8f} (tile {np.argmax(loss_diff)})\")\n",
    "    print(f\"Max loss decrease: {np.min(loss_diff):.8f} (tile {np.argmin(loss_diff)})\")\n",
    "    print()\n",
    "    \n",
    "    # 找出损失增加最多的tiles\n",
    "    if len(increased_tiles) > 0:\n",
    "        print(\"Top 10 tiles with highest loss increase:\")\n",
    "        sorted_increase_indices = increased_tiles[np.argsort(loss_diff[increased_tiles])[::-1]][:10]\n",
    "        print(f\"{'Tile Index':<12} {'Before':<15} {'After':<15} {'Increase':<15} {'% Change':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        for idx in sorted_increase_indices:\n",
    "            before = orig_np[idx]\n",
    "            after = rot_np[idx]\n",
    "            increase = loss_diff[idx]\n",
    "            pct_change = loss_change_percent[idx]\n",
    "            print(f\"{idx:<12} {before:<15.8f} {after:<15.8f} {increase:<15.8f} {pct_change:<12.2f}\")\n",
    "        print()\n",
    "    \n",
    "    # 找出损失减少最多的tiles\n",
    "    if len(decreased_tiles) > 0:\n",
    "        print(\"Top 10 tiles with highest loss decrease:\")\n",
    "        sorted_decrease_indices = decreased_tiles[np.argsort(loss_diff[decreased_tiles])][:10]\n",
    "        print(f\"{'Tile Index':<12} {'Before':<15} {'After':<15} {'Decrease':<15} {'% Change':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        for idx in sorted_decrease_indices:\n",
    "            before = orig_np[idx]\n",
    "            after = rot_np[idx]\n",
    "            decrease = loss_diff[idx]\n",
    "            pct_change = loss_change_percent[idx]\n",
    "            print(f\"{idx:<12} {before:<15.8f} {after:<15.8f} {decrease:<15.8f} {pct_change:<12.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'increased_tiles': increased_tiles,\n",
    "        'decreased_tiles': decreased_tiles,\n",
    "        'loss_diff': loss_diff,\n",
    "        'loss_change_percent': loss_change_percent,\n",
    "        'loss_ratio': loss_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6b18b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_largest_to_groups(sorted_idx, block_size):\n",
    "    N = sorted_idx.shape[-1]\n",
    "    num_groups = N // block_size\n",
    "    grouped_idx = torch.empty_like(sorted_idx)\n",
    "    for i in range(N):\n",
    "        group = i % num_groups\n",
    "        pos_in_group = i // num_groups\n",
    "        grouped_idx[group * block_size + pos_in_group] = sorted_idx[i]\n",
    "    return grouped_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d2ae9a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[186]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sorted_roted_t =  hadamard_transform(\u001b[43msorted_token\u001b[49m.reshape(-\u001b[32m1\u001b[39m, sorted_token.shape[\u001b[32m0\u001b[39m] // \u001b[32m32\u001b[39m,\n\u001b[32m      2\u001b[39m                                                       \u001b[32m32\u001b[39m), scale=\u001b[32m1\u001b[39m / math.sqrt(\u001b[32m32\u001b[39m)).reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m sorted_p_rt1 = quantize_mx_op(sorted_roted_t,\n\u001b[32m      4\u001b[39m                       mx_specs,\n\u001b[32m      5\u001b[39m                       elem_format=\u001b[33m\"\u001b[39m\u001b[33mfp4_e2m1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m                       block_size=\u001b[32m32\u001b[39m,\n\u001b[32m      7\u001b[39m                       axes=-\u001b[32m1\u001b[39m,\n\u001b[32m      8\u001b[39m                       scale_mode=\u001b[32m0\u001b[39m,)\n",
      "\u001b[31mNameError\u001b[39m: name 'sorted_token' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_roted_t =  hadamard_transform(sorted_token.reshape(-1, sorted_token.shape[0] // 32,\n",
    "                                                      32), scale=1 / math.sqrt(32)).reshape(-1)\n",
    "sorted_p_rt1 = quantize_mx_op(sorted_roted_t,\n",
    "                      mx_specs,\n",
    "                      elem_format=\"fp4_e2m1\",\n",
    "                      block_size=32,\n",
    "                      axes=-1,\n",
    "                      scale_mode=0,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mx-qllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
